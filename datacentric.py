# -*- coding: utf-8 -*-
"""datacentric.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JrzKTjzkwp7cwL6-GAFRpvsp8oo0gyw4
"""

# Commented out IPython magic to ensure Python compatibility.
!pip install fasttext
!pip install datasets
!pip install WordCloud
!pip install shap
!pip install -U swifter

import pandas as pd

import csv
import fasttext 

from nltk.tokenize import word_tokenize
from nltk.corpus import stopwords
import re
from textblob import Word

import nltk
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')
nltk.download('omw-1.4')

import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import swifter

from nltk.stem.snowball import SnowballStemmer
from nltk.stem import WordNetLemmatizer

from urllib.request import urlopen
from bs4 import BeautifulSoup

from wordcloud import WordCloud 
from datasets import load_dataset
from textblob import TextBlob

# %matplotlib inline
from sklearn.feature_extraction.text import CountVectorizer
import numpy as np
sns.set()

import sys

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report
from sklearn.ensemble import RandomForestRegressor
from sklearn.feature_extraction.text import TfidfVectorizer

import shap

# Lecture des fichiers sources et création d'un échantillon de test (à discuter)

dfx = pd.read_csv('drive/MyDrive/Colab Notebooks/x_baseline.csv') 
dfy = pd.read_csv('drive/MyDrive/Colab Notebooks/y_baseline.csv') 
df = pd.read_csv('drive/MyDrive/Colab Notebooks/full_train.csv', index_col = 0)
df_test1 = pd.read_csv('drive/MyDrive/Colab Notebooks/test_ens_sample.csv', index_col = 0) # seulement 10 lignes disponibles

# Proposition de construire un échantillon de train et test qui est basé sur les 8000 / 2000 première lignes 

df_train = df.iloc[2000:,:]
df_test = df.iloc[0:2000,:]
df_train.head()
#df['category'].value_counts()
#Le dataset est bien équilibré
#df.info()

"""# New Section"""

#Fonctions de tests données par l'ENS

def process_csv(df, output_name, output_folder):
    df.loc[:, 'text'] = '__label__' + df['category'].astype(str) + ' ' + df['review']
    output_file = f'{output_folder}/{output_name}.txt'
    df[['text']].to_csv(output_file, index=False, header=False, 
                quoting=csv.QUOTE_NONE,  quotechar="",  escapechar="\\")
    return output_file


def train_model(df, df_test, output_folder):
    output_file = process_csv(df, 'train', output_folder)
    output_file_test = process_csv(df_test, 'test', output_folder)
    model = fasttext.train_supervised(
        input=output_file, lr=0.1, epoch=20, wordNgrams=2)
    results = model.test(output_file_test)
    accuracy = results[1]
    return accuracy

# Analyseur des mots les plus fréquents

chaine_mots = []


        

from collections import Counter
        
dico = Counter(chaine_mots) 
mots = [m[0] for m in dico.most_common(50)]
freq = [m[1] for m in dico.most_common(50)]
        



plt.figure(figsize= (20,20))
sns.barplot(y=mots, x=freq)

#Correction des mots avec fautes
words = pd.read_csv('drive/MyDrive/Colab Notebooks/words_alpha.txt')

liste = []

for a in words.a:
    liste.append(a)
    
def correct(mots):
    listwords_corrected = []
    mots = word_tokenize(mots)
    for mot in mots:
        if mot in liste:
            listwords_corrected.append(mot)
        else:
            motacorriger = Word(mot)
            listwords_corrected.append(motacorriger.correct())
    listwords_corrected = list_to_string(listwords_corrected)
    return listwords_corrected

test_correct = df_train['review'].iloc[0]
print(test_correct)
test_correct = TextBlob(test_correct).correct()
print(test_correct)

def list_to_string (liste):
    str = ""
    for mot in liste:
        str = str + " " + mot
    return str

#Racinisation des différents mots
def stemming(mots):
    mots = word_tokenize(mots)
    stemmer = SnowballStemmer(language="english")
    racine = []
    for mot in mots:
        rac = stemmer.stem(mot)
        if rac not in racine:
            racine.append(rac)
    racine = list_to_string(racine)
    return racine

test_stemming = df_train['review'].iloc[0]
print(test_stemming)
print(stemming(test_stemming))

#Lemmatisation des différents mots

def lemming(mots):
    wordnet_lemmatizer = WordNetLemmatizer()
    mots = word_tokenize(mots)
    lemme = []
    for mot in mots:
        lem = wordnet_lemmatizer.lemmatize(mot, pos='v')
        if lem not in lemme:
            lemme.append(lem)
    lemme = list_to_string(lemme)        
    return lemme

test_lemming = df_train['review'].iloc[0]
print(test_lemming)
print(lemming(test_lemming))

#Tout en minuscule
def lowchar(mots):        
    return mots.lower()

test_lowchar = df_train['review'].iloc[0]
print(test_lowchar)
print(lowchar(test_lowchar))

#suppression des stop words 
stop_words = set(stopwords.words('english'))
stop_words.update([",", ".",'-','"',' '' ','...'])
stop_words.update(['film', 'movie', 'really', 'plot', 'br', 'one', 'show', 'movies'])

def remove_stopwords(mots):
    mots = word_tokenize(mots) 
    new_str = []
    for mot in mots:
        if mot not in stop_words:
            new_str.append(mot)
    new_str = list_to_string(new_str)                
    return new_str

test_remove_stopwords = df_train['review'].iloc[0]
print(test_remove_stopwords)
print(remove_stopwords(test_remove_stopwords))

#Récupération des mots d'au moins 3 lettres
real_words = re.compile('[a-zA-Z0-9]{3,}')

def remove_non_words(string):   
    new_str = []
    string = string.split(" ")    
    for word in string:
        real_word = real_words.findall(word)
        #print(real_word)
        real_word = list_to_string(real_word)
        if (real_word != None) and (real_word != ''):
            new_str.append(real_word)
    new_str = list_to_string(new_str)                        
    return new_str

test_remove_non_words = df_train['review'].iloc[0]
print(test_remove_non_words)
print(remove_non_words(test_remove_non_words))

#Removing the html strips
def strip_html(text):
    soup = BeautifulSoup(text, "html.parser")
    return soup.get_text()

#Removing the square brackets
def remove_between_square_brackets(text):
    return re.sub('\[[^]]*\]', '', text)

#Define function for removing special characters
def remove_special_characters(text, remove_digits=True):
    pattern=r'[^a-zA-z0-9\s]'
    text=re.sub(pattern,'',text)
    return text

#Removing the noisy text
def denoise_text(text):
    text = strip_html(text)
    text = remove_between_square_brackets(text)
    text = remove_special_characters(text)
    return text

test_preprocessing = df_train['review'].iloc[15]
print(test_preprocessing)
strip_html(test_preprocessing)
remove_between_square_brackets(test_preprocessing)
denoise_text(test_preprocessing)
remove_special_characters(test_preprocessing)
print(test_preprocessing)

from collections import Counter

def words(text): return re.findall(r'\w+', text.lower())

WORDS = Counter(words(open('big.txt').read()))

def P(word, N=sum(WORDS.values())): 
    "Probability of `word`."
    return WORDS[word] / N

def correction(word): 
    "Most probable spelling correction for word."
    return max(candidates(word), key=P)

def candidates(word): 
    "Generate possible spelling corrections for word."
    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])

def known(words): 
    "The subset of `words` that appear in the dictionary of WORDS."
    return set(w for w in words if w in WORDS)

def edits1(word):
    "All edits that are one edit away from `word`."
    letters    = 'abcdefghijklmnopqrstuvwxyz'
    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]
    deletes    = [L + R[1:]               for L, R in splits if R]
    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]
    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]
    inserts    = [L + c + R               for L, R in splits for c in letters]
    return set(deletes + transposes + replaces + inserts)

def edits2(word): 
    "All edits that are two edits away from `word`."
    return (e2 for e1 in edits1(word) for e2 in edits1(e1))

def wordcloud(X_train):
    wc = WordCloud(background_color="white", max_words=200, stopwords = stop_words, max_font_size=50, random_state=42)
    X_pos = X_train[X_train.category == 1]
    X_neg = X_train[X_train.category == 0]
    text_pos = ""
    for e in X_pos.review : text_pos += e
    text_neg = ""
    for e in X_neg.review : text_neg += e

    plt.figure(figsize= (20,10)) 
    plt.subplot(211)
    wc.generate(text_pos)           
    plt.imshow(wc) 
    plt.show()

    plt.figure(figsize= (20,10)) 
    plt.subplot(221)
    wc.generate(text_neg)           
    plt.imshow(wc) 
    plt.show()

#Dataset de commentaires de films issus de IMDB associés à un sentiment positif ou négatif

dataset_imdb = load_dataset("imdb")
s_imdb  = pd.Series(dataset_imdb,index=dataset_imdb.keys())
df_train_imdb = pd.DataFrame(s_imdb.train)
df_test_imdb = pd.DataFrame(s_imdb.test)
df_train_imdb['label'].value_counts()
df_train_imdb.rename(columns = {'text': 'review', 'label': 'category'}, inplace=True)
df_test_imdb.rename(columns = {'text': 'review', 'label': 'category'}, inplace=True)
df_train_imdb['category'].value_counts()
df_test_imdb['category'].value_counts()
df_train_imdb.head()
#Le dataset est bien équilibré

com = df_train_imdb['review'].iloc[0]
print(com)

#Dataset de commentaires de films issus de allocine associés à un sentiment positif ou négatif
#ATTENTION commentaires en francais

dataset_allocine = load_dataset("allocine")
s_allocine  = pd.Series(dataset_allocine,index=dataset_imdb.keys())
df_train_allocine = pd.DataFrame(s_allocine.train)
df_test_allocine = pd.DataFrame(s_allocine.test)
df_train_allocine.rename(columns = {'label': 'category'}, inplace=True)
df_test_allocine.rename(columns = {'label': 'category'}, inplace=True)
df_train_allocine['category'].value_counts()
df_test_allocine['category'].value_counts()
#df_train_allocine.head()
#Le dataset est bien équilibré

#Autre dataset issu de IMDB de 50k de reviews

df_imdb_2 = pd.read_csv('drive/MyDrive/Colab Notebooks/IMDB Dataset.csv')
df_imdb_2.info()
df_imdb_2['sentiment'].value_counts()
df_imdb_2.rename(columns = {'sentiment': 'category'}, inplace=True)
df_imdb_2 = df_imdb_2.replace('positive', 1)
df_imdb_2 = df_imdb_2.replace('negative', 0)
df_imdb_2.astype({'category':int})
df_imdb_2['category'].value_counts()
df_imdb_2.head()
#Le dataset est bien équilibré

wordcloud(df_train)
df_train.info()

df_train.review = df_train.review.apply(lambda x: lowchar(x))
df_train.review = df_train.review.apply(lambda x: denoise_text(x))
df_train.review = df_train.review.apply(lambda x: remove_non_words(x))
df_train.review = df_train.review.apply(lambda x: remove_stopwords(x))
df_train.review = df_train.review.apply(lambda x: stemming(x))
df_train.review = df_train.review.apply(lambda x: lemming(x))

wordcloud(df_train)
df_train.info()

df_train_corrected = df_train.copy()

df_train_corrected.review = df_train_corrected.review.swifter.progress_bar(True).apply(lambda x: str(TextBlob(x).correct()))
#utiliser package swifter

wordcloud(df_train_corrected)

df_train.isna().sum()

df_train['length'] = df_train['review'].str.len()
df_train.review = df_train.review.apply(lambda x: denoise_text(x))

fig, ax = plt.subplots(figsize=[15,8])
sns.boxplot(x="category", y="length", hue="review", data=df_train, ax=ax)
plt.show()
#utiliser package swifter

def find_chain_exclamation(text):
    r = re.compile(r"(\! ){2,}")
    exclamation = r.findall(text)
    return len(exclamation)

def find_chain_interogation(text):
    r = re.compile(r"(\? ){2,}")
    interogation = r.findall(text)
    return len(interogation)

df_train['chain_exclamation'] = df_train.review.apply(lambda x: find_chain_exclamation(x))
df_train['chain_interogation'] = df_train.review.apply(lambda x: find_chain_interogation(x))

fig, ax = plt.subplots(figsize=[15,8])
sns.violinplot(x="category", y="chain_exclamation", data=df_train, ax=ax)
sns.violinplot(x="category", y="chain_interogation", data=df_train, ax=ax)
plt.show()

def return_ngram(texts, ngram_range=(1,1)):
    vectorizer = CountVectorizer(stop_words=stopwords.words('english'), ngram_range=ngram_range)
    vectorizer.fit(texts)
    count_list = np.array(vectorizer.transform(texts).sum(0))[0]
    count_words = list(zip(vectorizer.get_feature_names(), count_list))

    count_words = sorted(count_words, key=lambda x: x[1], reverse=True)

    count_words = pd.DataFrame(count_words, columns=['word', 'count'])
    return count_words

df_train = df.iloc[2000:,:]

count_words_pos1 = return_ngram(df_train[df_train['category'] == 1].review, ngram_range=(1,1))
count_words_neg1 = return_ngram(df_train[df_train['category'] == 0].review, ngram_range=(1,1))
count_words_pos2 = return_ngram(df_train[df_train['category'] == 1].review, ngram_range=(2,2))
count_words_neg2 = return_ngram(df_train[df_train['category'] == 0].review, ngram_range=(2,2))
count_words_pos3 = return_ngram(df_train[df_train['category'] == 1].review, ngram_range=(3,3))
count_words_neg3 = return_ngram(df_train[df_train['category'] == 0].review, ngram_range=(3,3))

plt.figure(figsize=(15,10))
plt.subplot(321)
sns.barplot('count', 'word', data=count_words_pos1.head(10))

plt.figure(figsize=(15,10))
plt.subplot(322)
sns.barplot('count', 'word', data=count_words_neg1.head(10))

plt.figure(figsize=(15,10))
plt.subplot(323)
sns.barplot('count', 'word', data=count_words_pos2.head(10))

plt.figure(figsize=(15,10))
plt.subplot(324)
sns.barplot('count', 'word', data=count_words_neg2.head(10))

plt.figure(figsize=(15,10))
plt.subplot(325)
sns.barplot('count', 'word', data=count_words_pos3.head(10))

plt.figure(figsize=(15,10))
plt.subplot(326)
sns.barplot('count', 'word', data=count_words_neg3.head(10))

plt.show()

functions_list = []
functions_list.append(lowchar)
functions_list.append(denoise_text)
functions_list.append(remove_non_words)
functions_list.append(remove_stopwords)
functions_list.append(stemming)
functions_list.append(lemming)

def pipeline(text):
    for i in range(len(functions_list)):
        text = functions_list[i](text)
    return text

test_pipeline = df['review'].iloc[0]
#print(test_pipeline)

test_pipeline = pipeline(test_pipeline)
print(test_pipeline)

df_train = df.iloc[2000:,:]
df_copy = df_train.copy()

print("l'accuracy intiale est :",train_model(df_copy, df_test,'drive/MyDrive/Colab Notebooks/'))

for i in range(len(functions_list)):
    df_copy.review = df_copy.review.apply(lambda x: functions_list[i](x))
    print("l'accuracy de la fonction ", i+1, "est :",train_model(df_copy, df_test,'drive/MyDrive/Colab Notebooks/'))

count_words_pos1 = return_ngram(df_copy[df_copy['category'] == 1].review, ngram_range=(1,1))
count_words_neg1 = return_ngram(df_copy[df_copy['category'] == 0].review, ngram_range=(1,1))
count_words_pos2 = return_ngram(df_copy[df_copy['category'] == 1].review, ngram_range=(2,2))
count_words_neg2 = return_ngram(df_copy[df_copy['category'] == 0].review, ngram_range=(2,2))
count_words_pos3 = return_ngram(df_copy[df_copy['category'] == 1].review, ngram_range=(3,3))
count_words_neg3 = return_ngram(df_copy[df_copy['category'] == 0].review, ngram_range=(3,3))

plt.figure(figsize=(15,10))
plt.subplot(321)
sns.barplot('count', 'word', data=count_words_pos1.head(10))

plt.figure(figsize=(15,10))
plt.subplot(322)
sns.barplot('count', 'word', data=count_words_neg1.head(10))

plt.figure(figsize=(15,10))
plt.subplot(323)
sns.barplot('count', 'word', data=count_words_pos2.head(10))

plt.figure(figsize=(15,10))
plt.subplot(324)
sns.barplot('count', 'word', data=count_words_neg2.head(10))

plt.figure(figsize=(15,10))
plt.subplot(325)
sns.barplot('count', 'word', data=count_words_pos3.head(10))

plt.figure(figsize=(15,10))
plt.subplot(326)
sns.barplot('count', 'word', data=count_words_neg3.head(10))

plt.show()

df_train = df.iloc[2000:,:]
df_train_sum = pd.concat([df_train, df_train_imdb, df_imdb_2])

print("l'accuracy intiale est :",train_model(df_train_sum, df_test,'drive/MyDrive/Colab Notebooks/'))

for i in range(len(functions_list)):
    df_train_sum.review = df_train_sum.review.apply(lambda x: functions_list[i](x))
    print("l'accuracy de la fonction ", i+1, "est :",train_model(df_train_sum, df_test,'drive/MyDrive/Colab Notebooks/'))

df_train = df.iloc[2000:,:]
df_copy = df_train.copy()

print("l'accuracy intiale est :",train_model(df_copy, df_test,'drive/MyDrive/Colab Notebooks/'))
accur_init = train_model(df_copy, df_test,'drive/MyDrive/Colab Notebooks/')

functions_list_optim = []
functions_list_tmp = functions_list
accur_optim = []
accur_optim.append(accur_init)

#Construction d'une liste optimale des fonctions en prenant, à chaque étape,
#la fonction qui optimise l'accuracy
for j in range(len(functions_list)):
    #Génération de la base de départ  
    df_train = df.iloc[2000:,:]
    
    #Application aux données la liste des meilleures fonctions déjà trouvée
    for i in range(len(functions_list_optim)):
        df_copy.review = df_copy.review.apply(lambda x: functions_list_optim[i](x))

    #On recherche la meilleure fonction suivante avec cette base de données
    accur = []
    for i in range(len(functions_list_tmp)):
        #df_copy = df_train
        df_copy.review = df_copy.review.apply(lambda x: functions_list_tmp[i](x))
        accur.append(train_model(df_copy, df_test,'drive/MyDrive/Colab Notebooks/'))

    accur_optim.append(max(accur))  
    functions_list_optim.append(functions_list_tmp[accur.index(max(accur))])
    functions_list_tmp.pop(accur.index(max(accur)))

print(functions_list_optim)    
print(accur_optim)

df_train = df.iloc[2000:,:]
df_copy = df_train.copy()

print("l'accuracy intiale est :",train_model(df_copy, df_test,'drive/MyDrive/Colab Notebooks/'))

for i in range(len(functions_list_optim)):
    df_copy.review = df_copy.review.apply(lambda x: functions_list_optim[i](x))
    print("l'accuracy de la fonction ", i+1, "est :",train_model(df_copy, df_test,'drive/MyDrive/Colab Notebooks/'))

functions_list = []
functions_list.append(lowchar)
functions_list.append(denoise_text)
functions_list.append(remove_non_words)
functions_list.append(remove_stopwords)
functions_list.append(stemming)
functions_list.append(lemming)

df_train = df.iloc[2000:,:]
df_copy = df_train.copy()

print("l'accuracy intiale est :",train_model(df_copy, df_test,'drive/MyDrive/Colab Notebooks/'))
accur_init = train_model(df_copy, df_test,'drive/MyDrive/Colab Notebooks/')

functions_list_optim = []
functions_list_tmp = functions_list
accur_optim = []
accur_optim.append(accur_init)

#Construction d'une liste optimale des fonctions en prenant, à chaque étape,
#la fonction qui optimise l'accuracy
for j in range(len(functions_list)):
    #Génération de la base de départ  
    df_train = df.iloc[2000:,:]
    df_copy = df_train.copy()

    #Application aux données la liste des meilleures fonctions déjà trouvée
    for i in range(len(functions_list_optim)):
        df_copy.review = df_copy.review.apply(lambda x: functions_list_optim[i](x))

    #On recherche la meilleure fonction suivante avec cette base de données
    accur = []
    for i in range(len(functions_list_tmp)):
        df_copy.review = df_copy.review.apply(lambda x: functions_list_tmp[i](x))
        accur.append(train_model(df_copy, df_test,'drive/MyDrive/Colab Notebooks/'))
    #Si l'application de l'une des fonctions restantes n'améliorent pas le résultat, l'exécution est stoppée      
    if (max(accur) < accur_optim[-1]):
        print('Le maximum d\'accuracy calculée à la dernière étape est :', max(accur))
        print('La dernière accuracy optimisée calculée est :', accur_optim[-1])
        sys.exit("Optimisation atteinte, les fonctions restantes dégradent le résultat.")     
    accur_optim.append(max(accur))  
    functions_list_optim.append(functions_list_tmp[accur.index(max(accur))])
    functions_list_tmp.pop(accur.index(max(accur)))

print(functions_list_optim)    
print(accur_optim)

functions_list = []
functions_list.append(lowchar)
functions_list.append(denoise_text)
functions_list.append(remove_non_words)
functions_list.append(remove_stopwords)
functions_list.append(stemming)
functions_list.append(lemming)

df_train = df.iloc[2000:,:]
df_train_sum = pd.concat([df_train, df_train_imdb, df_imdb_2])

print("l'accuracy intiale est :",train_model(df_train_sum, df_test,'drive/MyDrive/Colab Notebooks/'))
accur_init = train_model(df_train_sum, df_test,'drive/MyDrive/Colab Notebooks/')

functions_list_optim = []
functions_list_tmp = functions_list
accur_optim = []
accur_optim.append(accur_init)

#Même algorithme que précédent en utilisant les données supplémentaires
for j in range(len(functions_list)):
    #Génération de la base de départ  
    df_train = df.iloc[2000:,:]
    df_train_sum = pd.concat([df_train, df_train_imdb, df_imdb_2])

    #Application aux données la liste des meilleures fonctions déjà trouvée
    for i in range(len(functions_list_optim)):
        df_train_sum.review = df_train_sum.review.apply(lambda x: functions_list_optim[i](x))

    #On recherche la meilleure fonction suivante avec cette base de données
    accur = []
    for i in range(len(functions_list_tmp)):
        df_train_sum.review = df_train_sum.review.apply(lambda x: functions_list_tmp[i](x))
        accur.append(train_model(df_train_sum, df_test,'drive/MyDrive/Colab Notebooks/'))
    #Si l'application de l'une des fonctions restantes n'améliorent pas le résultat, l'exécution est stoppée      
    if (max(accur) < accur_optim[-1]):
        print('Le maximum d\'accuracy calculée à la dernière étape est :', max(accur))
        print('La dernière accuracy optimisée calculée est :', accur_optim[-1])
        sys.exit("Optimisation atteinte, les fonctions restantes dégradent le résultat.")     
    accur_optim.append(max(accur))  
    functions_list_optim.append(functions_list_tmp[accur.index(max(accur))])
    functions_list_tmp.pop(accur.index(max(accur)))

print(functions_list_optim)    
print(accur_optim)

df_copy = df_train_corrected.copy()

print("l'accuracy intiale est :",train_model(df_copy, df_test,'drive/MyDrive/Colab Notebooks/'))
accur_init = train_model(df_copy, df_test,'drive/MyDrive/Colab Notebooks/')

functions_list_optim = []
functions_list_tmp = functions_list
accur_optim = []
accur_optim.append(accur_init)

#Construction d'une liste optimale des fonctions en prenant, à chaque étape,
#la fonction qui optimise l'accuracy
for j in range(len(functions_list)):
    #Génération de la base de départ  
    df_train = df.iloc[2000:,:]
    
    #Application aux données la liste des meilleures fonctions déjà trouvée
    for i in range(len(functions_list_optim)):
        df_copy.review = df_copy.review.apply(lambda x: functions_list_optim[i](x))

    #On recherche la meilleure fonction suivante avec cette base de données
    accur = []
    for i in range(len(functions_list_tmp)):
        #df_copy = df_train
        df_copy.review = df_copy.review.apply(lambda x: functions_list_tmp[i](x))
        accur.append(train_model(df_copy, df_test,'drive/MyDrive/Colab Notebooks/'))

    accur_optim.append(max(accur))  
    functions_list_optim.append(functions_list_tmp[accur.index(max(accur))])
    functions_list_tmp.pop(accur.index(max(accur)))

print(functions_list_optim)    
print(accur_optim)

count_words_pos1 = return_ngram(df_train_corrected[df_train_corrected['category'] == 1].review, ngram_range=(1,1))
count_words_neg1 = return_ngram(df_train_corrected[df_train_corrected['category'] == 0].review, ngram_range=(1,1))
count_words_pos2 = return_ngram(df_train_corrected[df_train_corrected['category'] == 1].review, ngram_range=(2,2))
count_words_neg2 = return_ngram(df_train_corrected[df_train_corrected['category'] == 0].review, ngram_range=(2,2))
count_words_pos3 = return_ngram(df_train_corrected[df_train_corrected['category'] == 1].review, ngram_range=(3,3))
count_words_neg3 = return_ngram(df_train_corrected[df_train_corrected['category'] == 0].review, ngram_range=(3,3))

plt.figure(figsize=(15,10))
plt.subplot(321)
sns.barplot('count', 'word', data=count_words_pos1.head(10))

plt.figure(figsize=(15,10))
plt.subplot(322)
sns.barplot('count', 'word', data=count_words_neg1.head(10))

plt.figure(figsize=(15,10))
plt.subplot(323)
sns.barplot('count', 'word', data=count_words_pos2.head(10))

plt.figure(figsize=(15,10))
plt.subplot(324)
sns.barplot('count', 'word', data=count_words_neg2.head(10))

plt.figure(figsize=(15,10))
plt.subplot(325)
sns.barplot('count', 'word', data=count_words_pos3.head(10))

plt.figure(figsize=(15,10))
plt.subplot(326)
sns.barplot('count', 'word', data=count_words_neg3.head(10))

plt.show()

df_train = df.iloc[2000:,:]
df_train_sum = pd.concat([df_train, df_train_imdb, df_imdb_2])

wordcloud(df_train_sum)

df_train_sum.review = df_train_sum.review.apply(lambda x: remove_stopwords(x))
wordcloud(df_train_sum)

count_words_pos2 = return_ngram(df_train_sum[df_train_sum['category'] == 1].review, ngram_range=(2,2))
count_words_neg2 = return_ngram(df_train_sum[df_train_sum['category'] == 0].review, ngram_range=(2,2))
count_words_pos3 = return_ngram(df_train_sum[df_train_sum['category'] == 1].review, ngram_range=(3,3))
count_words_neg3 = return_ngram(df_train_sum[df_train_sum['category'] == 0].review, ngram_range=(3,3))

plt.figure(figsize=(15,10))
plt.subplot(321)
sns.barplot('count', 'word', data=count_words_pos1.head(10))

plt.figure(figsize=(15,10))
plt.subplot(322)
sns.barplot('count', 'word', data=count_words_neg1.head(10))

plt.figure(figsize=(15,10))
plt.subplot(323)
sns.barplot('count', 'word', data=count_words_pos2.head(10))

plt.figure(figsize=(15,10))
plt.subplot(324)
sns.barplot('count', 'word', data=count_words_neg2.head(10))

plt.figure(figsize=(15,10))
plt.subplot(325)
sns.barplot('count', 'word', data=count_words_pos3.head(10))

plt.figure(figsize=(15,10))
plt.subplot(326)
sns.barplot('count', 'word', data=count_words_neg3.head(10))

plt.show()

count_words_pos10 = return_ngram(df_train_sum[df_train_sum['category'] == 1].review, ngram_range=(5,5))
count_words_neg10 = return_ngram(df_train_sum[df_train_sum['category'] == 0].review, ngram_range=(5,5))


plt.figure(figsize=(15,10))
plt.subplot(211)
sns.barplot('count', 'word', data=count_words_pos10.head(10))

plt.figure(figsize=(15,10))
plt.subplot(212)
sns.barplot('count', 'word', data=count_words_neg10.head(10))

plt.show()

#Regarder les textes comprenant ces occurences des listes de mots

print("l'accuracy intiale est :",train_model(df_train_corrected, df_test,'drive/MyDrive/Colab Notebooks/'))

for i in range(len(functions_list_optim)):
    df_train_corrected.review = df_train_corrected.review.apply(lambda x: functions_list_optim[i](x))
    print("l'accuracy de la fonction ", i+1, "est :",train_model(df_train_corrected, df_test,'drive/MyDrive/Colab Notebooks/'))

df_train = df.iloc[2000:,:]
df_train_sum = pd.concat([df_train, df_train_imdb, df_imdb_2])
df_train = df_train_sum

vectorizer = CountVectorizer(max_features=2000, stop_words=stopwords.words('english'))

X_train = vectorizer.fit_transform(df_train.review)
X_test = vectorizer.transform(df_test.review)

# taille du vocabulaire
voc = vectorizer.vocabulary_
print('Vocabulary size: ', len(voc))

# Affichage d'un échantilllon du vocabulaire
print({k: voc[k] for k in list(voc)[:10]})

# Définition du modèle
rf = RandomForestClassifier(n_jobs=-1)

y_train = df_train.category
y_test = df_test.category
# Entraînement du modèle.
rf.fit(X_train, y_train)
# Afficher l'accuracy sur le jeu de données de test.
rf.score(X_test, y_test)

# Affichage d'un rapport de classification
y_pred = rf.predict(X_test)
print(classification_report(y_test, y_pred))

pd.crosstab(y_test, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)

y_pred = rf.predict(X_test)
data = pd.DataFrame({'category': y_test.values})
data['y_pred'] = y_pred
fig, ax = plt.subplots(figsize=[15,8])
sns.violinplot(x="category", y="y_pred", data=data, ax=ax)
plt.show()
#Regarder les proba rf.predict_proba

# Application de TF-IDF à l'échantillon
df_train_sample = df_train['review'].iloc[0]
df_train_sample = [df_train_sample]
tf_idf = TfidfVectorizer()
X = tf_idf.fit_transform(df_train_sample)

print(df_train_sample)
# Affichage du vocabulaire
print('Vocabulary: \n', tf_idf.vocabulary_)

# Matrice résultante
pd.DataFrame(X.toarray(), columns=tf_idf.get_feature_names())

vectorizer = TfidfVectorizer(max_features=5000, stop_words=stopwords.words('english'), ngram_range=(2,4))
X_train = vectorizer.fit_transform(df_train.review)
X_test = vectorizer.transform(df_test.review)
y_train = df_train.category
y_test = df_test.category

# Définition du modèle
rf = RandomForestRegressor(n_jobs=-1)
# Entraînement du modèle.
rf.fit(X_train, y_train)
# Afficher le coefficient de détermination sur le jeu de données de test.
rf.score(X_test, y_test)

#Utiliser une classification

y_pred = rf.predict(X_test)
abs(y_test.values-y_pred).mean()

y_pred = rf.predict(X_test)
data = pd.DataFrame({'category': y_test.values})
data['y_pred'] = y_pred
fig, ax = plt.subplots(figsize=[15,8])
sns.violinplot(x="category", y="y_pred", data=data, ax=ax)
plt.show()

explainer = shap.TreeExplainer(rf, data=X_test.toarray())
shap_values = explainer.shap_values(X_test.todense(), approximate=True)

print('Expected Value:', explainer.expected_value)
pd.DataFrame(shap_values).head()

shap.summary_plot(shap_values, X_test, feature_names=vectorizer.get_feature_names(), plot_type="bar")

shap.summary_plot(shap_values, X_test.toarray(), feature_names=vectorizer.get_feature_names())

shap.initjs()
idx = 20
print(X_test[idx])

#utiliser un X_test_text avant la vectorisation pour ce calcul

print('\nPrediction :', y_pred[idx])
shap.force_plot(explainer.expected_value, shap_values[idx], X_test[idx].toarray()[0], feature_names=vectorizer.get_feature_names())

shap.initjs()
idx = 20
print(X_test[idx])

#utiliser un X_test_text avant la vectorisation pour ce calcul

print('\nPrediction :', y_pred[idx])
shap.force_plot(explainer.expected_value, shap_values[idx], X_test[idx].toarray()[0], feature_names=vectorizer.get_feature_names())

functions_list = []
functions_list.append(lowchar)
functions_list.append(denoise_text)
functions_list.append(remove_non_words)
functions_list.append(remove_stopwords)
functions_list.append(stemming)
functions_list.append(lemming)

# Définition du modèle
rf = RandomForestClassifier(n_jobs=-1)
X_train = df_train.review
X_test = vectorizer.transform(df_test.review)

y_train = df_train.category
y_test = df_test.category
print(X_train.iloc[0])

for i in range(len(functions_list)):
    X_train = df_train.review
    X_train = X_train.apply(lambda x:functions_list[i](x))
    X_train = vectorizer.fit_transform(X_train)
    rf.fit(X_train, y_train)
    print ('score à l\'étape ', i, ' : '),rf.score(X_test, y_test)
    y_pred = rf.predict(X_test)
    print('Erreur moyenne: ', abs(y_test.values-y_pred).mean())

# Entraînement du modèle.
# Afficher l'accuracy sur le jeu de données de test.

df_train = df.iloc[2000:,:]
df_train_sum = pd.concat([df_train, df_train_imdb, df_imdb_2])
vectorizer = TfidfVectorizer(max_features=5000, stop_words=stopwords.words('english'), ngram_range=(2,4))

# Définition du modèle
rf = RandomForestClassifier(n_jobs=-1)
X_train = df_train_sum.review

y_train = df_train_sum.category
y_test = df_test.category
print(X_train.iloc[0])

for i in range(len(functions_list)):
    X_train = df_train_sum.review
    X_train = X_train.apply(lambda x:functions_list[i](x))
    X_train = vectorizer.fit_transform(X_train)
    rf.fit(X_train, y_train)
    print ('score à l\'étape ', i, ' : ')
    rf.score(X_test, y_test)
    y_pred = rf.predict(X_test)
    print('Erreur moyenne: ', abs(y_test.values-y_pred).mean())
